{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huyton/opt/anaconda3/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/Users/huyton/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.48235, 0.45882, 0.40784]\n",
      "    std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n",
      "Epoch 1/10, Loss: 121.8297\n",
      "Epoch 2/10, Loss: 68.9590\n",
      "Epoch 3/10, Loss: 67.7728\n",
      "Epoch 4/10, Loss: 66.5114\n",
      "Epoch 5/10, Loss: 58.0027\n",
      "Epoch 6/10, Loss: 53.3400\n",
      "Epoch 7/10, Loss: 54.5931\n",
      "Epoch 8/10, Loss: 52.0841\n",
      "Epoch 9/10, Loss: 49.1581\n",
      "Epoch 10/10, Loss: 49.1417\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from network.network_pro import Inpaint\n",
    "from losses.perceptual import PerceptualLoss\n",
    "\n",
    "class InpaintingDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.imgs = os.listdir(img_dir)\n",
    "        self.masks = os.listdir(mask_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.imgs[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
    "\n",
    "        img = cv2.imread(img_path) / 255.0 # (256, 256, 3)\n",
    "        mask = cv2.imread(mask_path)[..., 0] / 255.0 # (256, 256, 3) => (256, 256)\n",
    "\n",
    "        img = torch.Tensor(img).permute(2, 0, 1).float()\n",
    "        mask = torch.Tensor(mask).unsqueeze(0).float()\n",
    "\n",
    "        return (img, mask), img                     # img (3, 256, 256), mask (1, 256, 256)\n",
    "\n",
    "train_dataset = InpaintingDataset('./samples/test_img_face', './samples/test_mask_face')\n",
    "train_loader = DataLoader(train_dataset, batch_size=2)\n",
    "\n",
    "def train(epochs, model, train_loader, criterion, optimizer, device):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            imgs, masks = inputs[0].to(device), inputs[1].to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs, masks)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "# configs\n",
    "epochs = 10\n",
    "model = Inpaint()\n",
    "criterion = PerceptualLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "train(epochs, model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_image = cv2.imread('./samples/test_img_face/1.png') / 255.0\n",
    "test_mask = cv2.imread('./samples/test_mask_face/1.png')[..., 0] / 255.0\n",
    "test_image = torch.Tensor(test_image).permute(2, 0, 1).float()\n",
    "test_mask = torch.Tensor(test_mask).unsqueeze(0).float()\n",
    "\n",
    "output = model(test_image.unsqueeze(0), test_mask.unsqueeze(0))\n",
    "output = output.squeeze(0).permute(1, 2, 0).detach().numpy() * 255\n",
    "cv2.imwrite('./temp/output.png', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./temp/test_image.png', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
